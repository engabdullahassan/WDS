{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDEFINE to use easily on differnt computers, define to path this file is\n",
    "\n",
    "#path for our github repositiory on local computer\n",
    "rep_path='/Users/User1/Documents/GitHub/Rep2' \n",
    "\n",
    "#Check if path correct & working in this path\n",
    "%cd $rep_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select camera\n",
    "cam_varr=0 #webcam\n",
    "#cam_varr=\"rtmp://live.restream.io/live/re_6588559_f67e5f9e60fe5b825de6\" #https://app.restream.io/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package to install. Once per envrionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependancy of face recognition\n",
    "%pip install CMake\n",
    "%pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing open cv face recognition api\n",
    "!pip3 install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API form Model Garden for TensorFlow, needed for object detection API\n",
    "#only need to run once\n",
    "%cd $rep_path/WDS \n",
    "!git clone https://github.com/tensorflow/models/\n",
    "%cd $rep_path/WDS/models/research\n",
    "\n",
    "#proto buffer compilation, Protobufs used to conifure modele and trainning parapemetres\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "#installing objeect dection api\n",
    "%cp object_detection/packages/tf2/setup.py . #tf2 \n",
    "\n",
    "!python -m pip install ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports. Every kerrnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING MODEL AND STARTING WEBCAM\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2  #real-time computer vision\n",
    "import os\n",
    "import face_recognition #libary for face rec\n",
    "\n",
    "#to supperress tf logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'   \n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "#supress tf logging\n",
    "tf.get_logger().setLevel('ERROR')    \n",
    "\n",
    "#for email\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm cv2 version\n",
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv2.getBuildInformation())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning face from sample image\n",
    "#excpetion for when face couldnt be detected in sample image\n",
    "try:\n",
    "    gaurd01_pic = face_recognition.load_image_file(\"gaurd_01.jpg\")\n",
    "    gaurd01_encoding = face_recognition.face_encodings(gaurd01_pic)[0]\n",
    "except IndexError:\n",
    "    print(\"Couldn't find face in sample image\")\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of face encodings\n",
    "known_gaurd_encodings = [\n",
    "    gaurd01_encoding\n",
    "]\n",
    "\n",
    "#array of face labels\n",
    "known_gaurd_label = [\n",
    "    \"gaurd01\"\n",
    "]\n",
    "\n",
    "#intalize varribles\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_label = []\n",
    "\n",
    "#for analyzing every other frame for speed preformance (face)\n",
    "analyze_this_frame = True\n",
    "\n",
    "#skping frames for performance (weapon)\n",
    "frames_per_cycle_w=2\n",
    "frame_count_w=1 #offset from face\n",
    "\n",
    "###defining paths of model##\n",
    "label_path=rep_path+'/WDS/data/label_map.pbtxt'\n",
    "configuration_path=rep_path+'/WDS/our_exported-models/our_model_2/pipeline.config'\n",
    "checkpoint_path=rep_path+'/WDS/our_exported-models/our_model_2/checkpoint'\n",
    "\n",
    "print(label_path)\n",
    "print(configuration_path)\n",
    "print(checkpoint_path)\n",
    "\n",
    "####loading model####\n",
    "\n",
    "#using GPU dynamic memory alloaton\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "#builging dection model and loading pipleine configuration\n",
    "configs = config_util.get_configs_from_pipeline_file(configuration_path)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "#restoring checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(checkpoint_path, 'ckpt-0')).expect_partial()\n",
    "\n",
    "#definig detection function too find wepaons in video\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
    "\n",
    "#for ploting loading labbel map dta\n",
    "cat_index = label_map_util.create_category_index_from_labelmap(label_path,use_display_name=True)\n",
    "\n",
    "#initial for messagee\n",
    "last_email_sent_time = 0\n",
    "current_time = time.time()\n",
    "\n",
    "# Define the send_email function\n",
    "def send_email(subject, body, from_email, to_email, password):\n",
    "    # Create a MIMEMultipart message\n",
    "    message = MIMEMultipart()\n",
    "    message[\"From\"] = from_email\n",
    "    message[\"To\"] = to_email\n",
    "    message[\"Subject\"] = subject\n",
    "\n",
    "    # Add body to email\n",
    "    message.attach(MIMEText(body, \"plain\"))\n",
    "\n",
    "    # Create SMTP session\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.starttls()\n",
    "    server.login(from_email, password)\n",
    "\n",
    "    # Send email\n",
    "    text = message.as_string()\n",
    "    server.sendmail(from_email, to_email, text)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####starting camera###\n",
    "\n",
    "vid = cv2.VideoCapture(cam_varr) #video feed webcame\n",
    "\n",
    "#geting frame size\n",
    "frame_width = int(vid.get(3))\n",
    "frame_height = int(vid.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "#for saving video\n",
    "#result = cv2.VideoWriter('WDSrecording.avi', cv2.VideoWriter_fourcc(*'MJPG'),10, size)\n",
    "\n",
    "while(vid.isOpened()): #video capture is initizalized\n",
    "    startTime=time.time()\n",
    "    ret, frame=vid.read() #reads video frame: ret=bool if available frame, frame=image array\n",
    "    frame_expanded = np.expand_dims(frame, axis=0)#match feed to deimisons of model\n",
    "    \n",
    "    ######DETECTING ELEMENTS##########\n",
    "    ##########DETECTING FACE######\n",
    "\n",
    "    #for analyzing every other frame for better speed preformance\n",
    "    if analyze_this_frame:\n",
    "        #to reducee frame size for speed perforomancee\n",
    "        tiny_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # RGB(facee rec uses) <-- BGR(open cv)\n",
    "        rgb_tiny_frame = cv2.cvtColor(tiny_frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # find locations of faces in frame\n",
    "        face_locations = face_recognition.face_locations(rgb_tiny_frame)\n",
    "\n",
    "        #getting encodings of located faces\n",
    "        face_encodings = face_recognition.face_encodings(rgb_tiny_frame, face_locations)\n",
    "\n",
    "        face_label = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # comparing facee encodings found iin frame to our face encodings\n",
    "            matches = face_recognition.compare_faces(known_gaurd_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            #assingingg to the most similar face\n",
    "            face_distances = face_recognition.face_distance(known_gaurd_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_gaurd_label[best_match_index]\n",
    "            face_label.append(name)\n",
    "\n",
    "    #Alternatng frames for face\n",
    "    analyze_this_frame = not analyze_this_frame\n",
    "    ##########END DETECTING FACE######\n",
    "\n",
    "    ##########DETECTING WEAPON######\n",
    "    if (frame_count_w%frames_per_cycle_w)==0:\n",
    "      in_tensor = tf.convert_to_tensor(np.expand_dims(frame, 0), dtype=tf.float32)\n",
    "      detections, predictions_dict, shapes = detect_fn(in_tensor)\n",
    "      label_id_offset = 1\n",
    "    \n",
    "    #to skip certian frames\n",
    "    frame_count_w=frame_count_w+1\n",
    "    ##########END DETECTING WEAPON######\n",
    "    \n",
    "    #######END DETECTING ELEMENTS##########\n",
    "\n",
    "    # Showing results of face\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_label):\n",
    "        # with scale of orginal size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # create box \n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # labeling box\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        ##setting font\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        ##adding name\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Check if any weapons are detected\n",
    "    if  current_time - last_email_sent_time > 300:\n",
    "        # Check if it's been more than 5 minutes since the last email was sent\n",
    "        if detections['detection_scores'][0].numpy().any()>=0.5:\n",
    "            # Send an email alert\n",
    "            subject = \"Weapon detected!\"\n",
    "            body = \"A weapon has been detected in the building. Please investigate.\"\n",
    "            from_email = \"seniordesignaud2023@gmail.com\"\n",
    "            to_email = \"eng.abdullahmourad@gmail.com\"\n",
    "            password = \"ctvlttuynqzxtmbb\"\n",
    "            send_email(subject, body, from_email, to_email, password)\n",
    "            last_email_sent_time = current_time\n",
    "\n",
    "    #dRAWING BOX OF DEDETED OBJECT(weaapon)\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        frame,\n",
    "        detections['detection_boxes'][0].numpy(),\n",
    "        (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "        detections['detection_scores'][0].numpy(),\n",
    "        cat_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=300,\n",
    "        min_score_thresh=.20,\n",
    "        agnostic_mode=False)\n",
    "    \n",
    "\n",
    "    #Displaying footage to user\n",
    "    if not ret:\n",
    "         print(\"Exting. Didnt get frame\")\n",
    "         break\n",
    "    else:\n",
    "        #result.write(frame) #saving footage\n",
    "\n",
    "        #display video with results, resize to orginal ratio\n",
    "        cv2.imshow('WDS footage', cv2.resize(frame, size))\n",
    "\n",
    "        #press q to quit \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break \n",
    "\n",
    "###ending webcam###\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
